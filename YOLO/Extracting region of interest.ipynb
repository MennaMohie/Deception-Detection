{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Extracting region of interest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZS3IuPu_ZvN",
        "colab_type": "text"
      },
      "source": [
        "<h1>Extracting region of interest from each video (person)</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvFQ6Doy_ZvR",
        "colab_type": "text"
      },
      "source": [
        "<h2>Imports</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtuYFpwb_ZvT",
        "colab_type": "code",
        "outputId": "cde414c7-f5be-4937-e4a1-1045b6eebaad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        }
      },
      "source": [
        "!pip install cvlib\n",
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "import cvlib\n",
        "from cvlib.object_detection import draw_bbox\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting cvlib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/56/f57aa012b3fb8b22f46cc9016a7198d7571b82d21c8a257dfca8d387c99b/cvlib-0.2.5.tar.gz (10.0MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1MB 3.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cvlib) (1.18.4)\n",
            "Collecting progressbar\n",
            "  Downloading https://files.pythonhosted.org/packages/a3/a6/b8e451f6cff1c99b4747a2f7235aa904d2d49e8e1464e0b798272aa84358/progressbar-2.5.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from cvlib) (2.23.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from cvlib) (7.0.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from cvlib) (2.4.1)\n",
            "Requirement already satisfied: imutils in /usr/local/lib/python3.6/dist-packages (from cvlib) (0.5.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->cvlib) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->cvlib) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->cvlib) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->cvlib) (2.9)\n",
            "Building wheels for collected packages: cvlib, progressbar\n",
            "  Building wheel for cvlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cvlib: filename=cvlib-0.2.5-cp36-none-any.whl size=10044204 sha256=9aee3a188f4bce97f8fd8f3cfe3f5ca2c7f13b19fced8d54629386d675f32ff8\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/cb/43/ba188c823836640d8f22ee1f6ff792a0c83a8b66eabf52b219\n",
            "  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progressbar: filename=progressbar-2.5-cp36-none-any.whl size=12074 sha256=90011d9fd63030f7b1e9e755d334a4e43e550aaf7588dd2c780c6ed940470ee4\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/e9/6b/ea01090205e285175842339aa3b491adeb4015206cda272ff0\n",
            "Successfully built cvlib progressbar\n",
            "Installing collected packages: progressbar, cvlib\n",
            "Successfully installed cvlib-0.2.5 progressbar-2.5\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOf3oFwM_ZvY",
        "colab_type": "text"
      },
      "source": [
        "<h2>Helper functions</h2>\n",
        "\n",
        "This function loads the videos from a specified path and returns them in a list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-6hCLYJ_ZvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_videos_paths(path):\n",
        "    videos_paths = glob.glob(path + '/*[0-9].mp4')\n",
        "    videos_paths.sort()\n",
        "    return videos_paths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCmeJNyfbxr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_video_frames(video):\n",
        "    frames = []\n",
        "    width = video.get(3)\n",
        "    height = video.get(4)\n",
        "    success, frame = video.read()\n",
        "    while success:\n",
        "        frames.append(frame)\n",
        "        success, frame = video.read()\n",
        "    return frames, width, height"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFmsWPZq_Zvd",
        "colab_type": "text"
      },
      "source": [
        "Next, we implement the function that applies YOLO to find the bounding boxes of the persons in one video.\n",
        "\n",
        "This function returns a list containing the bounding boxes of each frame in one video.\n",
        "If more than one bounding box are found in one frame, the bouding boxes are merged to obtain one bounding box."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWY1kBd3_Zve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def yolo(frames):\n",
        "    # frames = get_video_frames(video)\n",
        "    bounding_boxes = []\n",
        "    # print('start')\n",
        "    for frame in frames:\n",
        "        bboxes, label, confidence = cvlib.detect_common_objects(frame)\n",
        "        bboxes_person = []\n",
        "        for bbox, label in zip(bboxes, label):\n",
        "            if label == 'person':\n",
        "                bboxes_person.append(bbox)\n",
        "        if len(bboxes_person) == 0:\n",
        "            continue\n",
        "        x_top_left = bboxes_person[0][0]\n",
        "        y_top_left = bboxes_person[0][1]\n",
        "        x_bottom_right = bboxes_person[0][2]\n",
        "        y_bottom_right = bboxes_person[0][3]\n",
        "        for i in range(1, len(bboxes_person)): # if more than one bbox, merge them\n",
        "            x_top_left = min(x_top_left, bboxes_person[i][0])\n",
        "            y_top_left = min(y_top_left, bboxes_person[i][1])\n",
        "            x_bottom_right = max(x_bottom_right, bboxes_person[i][2])\n",
        "            y_bottom_right = max(y_bottom_right, bboxes_person[i][3])\n",
        "        bbox = [x_top_left, y_top_left, x_bottom_right, y_bottom_right]\n",
        "        bounding_boxes.append(bbox)\n",
        "    return bounding_boxes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE-PfcNFToha",
        "colab_type": "text"
      },
      "source": [
        "This function finds the bounding box with the largest area."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOBesfQX_Zvj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_max_bounding_box(bounding_boxes):\n",
        "    max_bbox = []\n",
        "    max_bbox_area = -1\n",
        "    '''min_bbox = []\n",
        "    min_bbox_area = 1000000000000000'''\n",
        "    for bbox in bounding_boxes:\n",
        "        width = bbox[2] - bbox[0]\n",
        "        height = bbox[3] - bbox[1]\n",
        "        bbox_area = width * height\n",
        "        if bbox_area > max_bbox_area:\n",
        "            max_bbox_area = bbox_area\n",
        "            max_bbox = bbox\n",
        "        '''if bbox_area < min_bbox_area:\n",
        "            min_bbox_area = bbox_area\n",
        "            min_bbox = bbox'''\n",
        "    return max_bbox #, max_bbox_area, min_bbox, min_bbox_area"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T64lWeDwTu5T",
        "colab_type": "text"
      },
      "source": [
        "This function crops one video according to the input bounding_box. It also resizes the video to the required size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z-CXD6u_Zvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def crop_video(frames, width, height, bounding_box):\n",
        "    x_top_left = int(max(0, bounding_box[0] - 5))\n",
        "    y_top_left = int(max(0, bounding_box[1] - 5))\n",
        "    x_bottom_right = int(min(width - 1, bounding_box[2] + 5)) # video.get(3) = width\n",
        "    y_bottom_right = int(min(height - 1, bounding_box[3] + 5)) # video.get(4) = height\n",
        "    # frames = get_video_frames(video)\n",
        "    cropped_frames = []\n",
        "    for frame in frames:\n",
        "        cropped_frame = frame[y_top_left:y_bottom_right, x_top_left:x_bottom_right]\n",
        "        cropped_frames.append(cropped_frame)\n",
        "        # cv2.imshow('cropped frame', cropped_frame)\n",
        "        # cv2.waitKey()\n",
        "    return cropped_frames"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqU_eto2dqkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def yolo_main(videos_paths):\n",
        "    min_frames = 100000000\n",
        "    cropped_frames_per_video = []\n",
        "    for video_path in videos_paths:\n",
        "        print(video_path)\n",
        "        video = cv2.VideoCapture(video_path)\n",
        "        frames, width, height = get_video_frames(video)\n",
        "        # frames = frames[:3] # COMMENT THIS LINE AFTER TESTING\n",
        "        if len(frames) < min_frames:\n",
        "            min_frames = len(frames)\n",
        "        bboxes = yolo(frames)\n",
        "        print(len(bboxes))\n",
        "        max_bbox = get_max_bounding_box(bboxes)\n",
        "        print(max_bbox)\n",
        "        cropped_frames = crop_video(frames, width, height, max_bbox)\n",
        "        cropped_frames_per_video.append(cropped_frames)\n",
        "    return cropped_frames_per_video, min_frames"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCPaf70O_Zvs",
        "colab_type": "text"
      },
      "source": [
        "<h2>Reading videos</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhtSDBel_Zvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_paths():\n",
        "  path = '/content/gdrive/My Drive/Team\\'s Drive/Graduation Project/Project/Dataset/Clips'\n",
        "  truthful_videos_paths = get_videos_paths(path + '/Truthful')\n",
        "  deceptive_videos_paths = get_videos_paths(path + '/Deceptive')\n",
        "  return truthful_videos_paths, deceptive_videos_paths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88-PFoaphCeZ",
        "colab_type": "code",
        "outputId": "8431a831-d7dd-4e0c-cfe2-81ed157491f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "source": [
        "truthful_videos_paths, deceptive_videos_paths = get_paths()\n",
        "cropped_frames_per_true, min_true = yolo_main(truthful_videos_paths)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Team's Drive/Graduation Project/Project/Dataset/Clips/Truthful/trial_truth_001.mp4\n",
            "Downloading yolov3.cfg from https://github.com/arunponnusamy/object-detection-opencv/raw/master/yolov3.cfg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0% |                                                                        |\r"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading yolov3.weights from https://pjreddie.com/media/files/yolov3.weights\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClwK0lsNX0EK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cropped_frames_per_lie, min_lie = yolo_main(deceptive_videos_paths)\n",
        "minn = min(min_true, min_lie)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dDZSySrXK8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.mkdir('Truthful')\n",
        "for i in range(len(truthful_videos_paths)):\n",
        "    folder_name = 'Truthful/trial_truth_' + str(i + 1).zfill(3)\n",
        "    os.mkdir(folder_name)\n",
        "    sub_vids = len(cropped_frames_per_true[i]) // minn\n",
        "    print(sub_vids)\n",
        "    for k in range(sub_vids):\n",
        "        sub_video_num = str(k).zfill(3)\n",
        "        cropped_frames_slice = cropped_frames_per_true[i][k * minn : k * minn + minn]\n",
        "        print(cropped_frames_slice)\n",
        "        cropped_frames_np = np.array([np.array(cropped_frames) for cropped_frames in cropped_frames_slice])\n",
        "        np.save(folder_name + '/' + sub_video_num + '.npy', cropped_frames_np)\n",
        "    k += 1\n",
        "    remainder = len(cropped_frames_per_true[i]) % minn\n",
        "    if remainder > 0.5 * minn:\n",
        "        sub_video_num = str(k).zfill(3)\n",
        "        missing = minn - remainder\n",
        "        start_idx = len(cropped_frames_per_true[i]) - remainder - missing\n",
        "        cropped_frames_slice = cropped_frames_per_true[i][start_idx : len(cropped_frames_per_true[i])]\n",
        "        cropped_frames_np = np.array([np.array(cropped_frames) for cropped_frames in cropped_frames_slice])\n",
        "        np.save(folder_name + '/' + sub_video_num + '.npy', cropped_frames_np)\n",
        "        k += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l9jS0KKhgR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.mkdir('Deceptive')\n",
        "for i in range(len(deceptive_videos_paths)):\n",
        "    folder_name = 'Deceptive/trial_lie_' + str(i + 1).zfill(3)\n",
        "    os.mkdir(folder_name)\n",
        "    sub_vids = len(cropped_frames_per_lie[i]) // minn\n",
        "    print(sub_vids)\n",
        "    for k in range(sub_vids):\n",
        "        sub_video_num = str(k).zfill(3)\n",
        "        cropped_frames_slice = cropped_frames_per_lie[i][k * minn : k * minn + minn]\n",
        "        print(cropped_frames_slice)\n",
        "        cropped_frames_np = np.array([np.array(cropped_frames) for cropped_frames in cropped_frames_slice])\n",
        "        np.save(folder_name + '/' + sub_video_num + '.npy', cropped_frames_np)\n",
        "    k += 1\n",
        "    remainder = len(cropped_frames_per_lie[i]) % minn\n",
        "    if remainder > 0.5 * minn:\n",
        "        sub_video_num = str(k).zfill(3)\n",
        "        missing = minn - remainder\n",
        "        start_idx = len(cropped_frames_per_lie[i]) - remainder - missing\n",
        "        cropped_frames_slice = cropped_frames_per_lie[i][start_idx : len(cropped_frames_per_lie[i])]\n",
        "        cropped_frames_np = np.array([np.array(cropped_frames) for cropped_frames in cropped_frames_slice])\n",
        "        np.save(folder_name + '/' + sub_video_num + '.npy', cropped_frames_np)\n",
        "        k += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjqgL9D6PcD5",
        "colab_type": "code",
        "outputId": "32fc68d4-c0d7-4aff-c78e-9940634902fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        }
      },
      "source": [
        "!cp /content/Truthful /content/gdrive/\"My Drive\"\n",
        "!cp /content/Deceptive /content/gdrive/\"My Drive\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yipc8CuJUfDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}