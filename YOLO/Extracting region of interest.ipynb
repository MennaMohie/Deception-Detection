{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0t0dERaxvYZ0"
   },
   "source": [
    "# Imports & variable declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "colab_type": "code",
    "id": "NjqWueWvvYZ7",
    "outputId": "01c75d0d-ab85-448a-c067-18fb7f3dec03"
   },
   "outputs": [],
   "source": [
    "!pip install cvlib\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "import cvlib\n",
    "from cvlib.object_detection import draw_bbox\n",
    "from google.colab import files\n",
    "from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 43
    },
    "colab_type": "code",
    "id": "I63Z_XmDC621",
    "outputId": "e73f6f37-f94f-476c-ff42-15b0c2ed210f"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ueH2e58vYad"
   },
   "outputs": [],
   "source": [
    "dataset_path = '/content/gdrive/My Drive/Team\\'s Drive/Graduation Project/Project/Dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YIwT_2WMvYar"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NLOkeiC6vYau"
   },
   "source": [
    "## I/O related functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pO2w9BC_vYay"
   },
   "outputs": [],
   "source": [
    "def read_videos(path):\n",
    "    videos = []\n",
    "    videos_fps = []  # frames per second\n",
    "    videos_paths = glob.glob(path + '/*[0-9].mp4')\n",
    "    videos_paths.sort()\n",
    "    for video_path in videos_paths:\n",
    "        video = cv2.VideoCapture(video_path)\n",
    "        fps = video.get(cv2.CAP_PROP_FPS)\n",
    "        videos.append(video)\n",
    "        videos_fps.append(fps)\n",
    "    cv2.destroyAllWindows()\n",
    "    return videos, videos_fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DuKr9VKwvYba"
   },
   "outputs": [],
   "source": [
    "def read(video_class):\n",
    "    if video_class == 'lie':\n",
    "        videos= read_videos(dataset_path + '/Clips/Deceptive')\n",
    "    else:\n",
    "        videos = read_videos(dataset_path + '/Clips/Truthful')\n",
    "    return videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ubCEgayRvYbm"
   },
   "outputs": [],
   "source": [
    "def get_video_frames(video):\n",
    "    frames = []\n",
    "    width = video.get(3)\n",
    "    height = video.get(4)\n",
    "    success, frame = video.read()\n",
    "    while success:\n",
    "        frames.append(frame)\n",
    "        success, frame = video.read()\n",
    "    return frames, width, height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bCuY4VFTvYb5"
   },
   "source": [
    "## YOLO-related functions, for extracting the region of interest (person)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HBk_iMcCvYb9"
   },
   "source": [
    "### This function returns a list containing the bounding boxes of each frame in one video.\n",
    "If more than one bounding box are found in one frame, the bouding boxes are merged to obtain one bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QEjGrE8DvYcX"
   },
   "outputs": [],
   "source": [
    "def yolo(frames):\n",
    "    bounding_boxes = []\n",
    "    frame_no = 0\n",
    "    while frame_no < len(frames):\n",
    "        frame = frames[frame_no]\n",
    "        frame_no += 30\n",
    "        bboxes, label, confidence = cvlib.detect_common_objects(frame)\n",
    "        bboxes_person = []\n",
    "        for bbox, label in zip(bboxes, label):\n",
    "            if label == 'person':\n",
    "                bboxes_person.append(bbox)\n",
    "        if len(bboxes_person) == 0:\n",
    "            continue\n",
    "        x_top_left = bboxes_person[0][0]\n",
    "        y_top_left = bboxes_person[0][1]\n",
    "        x_bottom_right = bboxes_person[0][2]\n",
    "        y_bottom_right = bboxes_person[0][3]\n",
    "        for i in range(1, len(bboxes_person)): # if more than one bbox, merge them\n",
    "            x_top_left = min(x_top_left, bboxes_person[i][0])\n",
    "            y_top_left = min(y_top_left, bboxes_person[i][1])\n",
    "            x_bottom_right = max(x_bottom_right, bboxes_person[i][2])\n",
    "            y_bottom_right = max(y_bottom_right, bboxes_person[i][3])\n",
    "        bbox = [x_top_left, y_top_left, x_bottom_right, y_bottom_right]\n",
    "        bounding_boxes.append(bbox)\n",
    "    return bounding_boxes  # list of bboxes, each bbox is a list representing a bbox of each (i * 20)th frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PXUsyUlQvYct"
   },
   "source": [
    "### This function finds the bounding box with the largest area for one video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5a62dwD3vYc1"
   },
   "outputs": [],
   "source": [
    "def get_max_bounding_box(bounding_boxes):\n",
    "    max_bbox = []\n",
    "    max_bbox_area = -1\n",
    "    '''min_bbox = []\n",
    "    min_bbox_area = 1000000000000000'''\n",
    "    for bbox in bounding_boxes:\n",
    "        width = bbox[2] - bbox[0]\n",
    "        height = bbox[3] - bbox[1]\n",
    "        bbox_area = width * height\n",
    "        if bbox_area > max_bbox_area:\n",
    "            max_bbox_area = bbox_area\n",
    "            max_bbox = bbox\n",
    "        '''if bbox_area < min_bbox_area:\n",
    "            min_bbox_area = bbox_area\n",
    "            min_bbox = bbox'''\n",
    "    return max_bbox #, max_bbox_area, min_bbox, min_bbox_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5yuPb-HwvYdH"
   },
   "source": [
    "### This function crops a video according to the given bounding box and returns the cropped frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "32Itl3WWvYdL"
   },
   "outputs": [],
   "source": [
    "def crop_video(frames, width, height, bounding_box):\n",
    "    x_top_left = int(max(0, bounding_box[0] - 5))\n",
    "    y_top_left = int(max(0, bounding_box[1] - 5))\n",
    "    x_bottom_right = int(min(width - 1, bounding_box[2] + 5)) # video.get(3) = width\n",
    "    y_bottom_right = int(min(height - 1, bounding_box[3] + 5)) # video.get(4) = height\n",
    "    # frames = get_video_frames(video)\n",
    "    cropped_frames = []\n",
    "    for frame in frames:\n",
    "        cropped_frame = frame[y_top_left:y_bottom_right, x_top_left:x_bottom_right]\n",
    "        cropped_frames.append(cropped_frame)\n",
    "        #cv2.imshow('cropped frame', cropped_frame)\n",
    "        #cv2.waitKey()\n",
    "    return cropped_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lSkazq8uvYfD"
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deceptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 43
    },
    "colab_type": "code",
    "id": "y0jKWo77vYfR",
    "outputId": "4195bb96-8eff-4ced-80ec-b8228f6bb7ba"
   },
   "outputs": [],
   "source": [
    "deceptive_videos = read('lie')\n",
    "os.mkdir('/content/Deceptive')\n",
    "for i in tqdm(range(len(deceptive_videos))):\n",
    "    video = deceptive_videos[i]\n",
    "    frames, width, height = get_video_frames(video)\n",
    "    # frames = frames[:3] # COMMENT THIS LINE AFTER TESTING\n",
    "    bboxes = yolo(frames)  # list of lists(each inner list is a bbox)\n",
    "    max_bbox = get_max_bounding_box(bboxes)  # list of 4 integers\n",
    "    cropped_frames = crop_video(frames, width, height, max_bbox)\n",
    "    video_dir = '/content/Deceptive/trial_lie' + str(i + 1).zfill(3)\n",
    "    os.mkdir(video_dir)\n",
    "    for k in range(len(cropped_frames)):\n",
    "        cv2.imwrite(video_dir + '/' + str(k).zfill(4) + '.jpg', cropped_frames[k])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r /content/Deceptive /content/gdrive/\"My Drive\"/\"Team's Drive\"/\"Graduation Project\"/Project/Dataset/PostYOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Truthful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 43
    },
    "colab_type": "code",
    "id": "8tnE5ssqYU2k",
    "outputId": "4ce9c89d-59fc-411a-f1a5-fc80475ba08f"
   },
   "outputs": [],
   "source": [
    "truthful_videos = read('truth')\n",
    "os.mkdir('/content/Truthful')\n",
    "for i in tqdm(range(len(truthful_videos))):\n",
    "    video = truthful_videos[i]\n",
    "    frames, width, height = get_video_frames(video)\n",
    "    # frames = frames[:3] # COMMENT THIS LINE AFTER TESTING\n",
    "    bboxes = yolo(frames)  # list of lists(each inner list is a bbox)\n",
    "    max_bbox = get_max_bounding_box(bboxes)  # list of 4 integers\n",
    "    cropped_frames = crop_video(frames, width, height, max_bbox)\n",
    "    video_dir = '/content/Truthful/trial_truth' + str(i + 1).zfill(3)\n",
    "    os.mkdir(video_dir)\n",
    "    for k in range(len(cropped_frames)):\n",
    "        cv2.imwrite(video_dir + '/' + str(k).zfill(4) + '.jpg', cropped_frames[k])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r /content/Truthful /content/gdrive/\"My Drive\"/\"Team's Drive\"/\"Graduation Project\"/Project/Dataset/PostYOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "inT7pIsKW5Yw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "YOLO + Videos Extension.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
